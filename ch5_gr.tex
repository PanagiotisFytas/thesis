
\end{algorithm}

\end{frame}

\begin{frame} {Frontier Partitioning}

\SetKwProg{Fn}{Function}{}{}
\SetKwHangingKw{Let}{let}
\begin{algorithm}[H]
    \label{partition}
    \Fn{partition($Frontier$, $N$)}{
        \For{all E $\in$ Frontier}{
            \While{$total\_backtrack\_entries(E) > 1$ \textbf{and} $size(Frontier) < N$}{
                $E' \leftarrow $ \textnormal{the smallest prefix of $E$
                that has a backtrack entry} \;
                $p \leftarrow \textnormal{ a process} \in backtrack(E') $\;
                $E_c' \leftarrow \textnormal{ a copy of } E'$\;
                \textnormal{remove $p$ from $ backtrack(E')$}\;
                \textnormal{add $p$ to $ sleep(E')$}\;
                \textnormal{add $ backtrack(E') $ to $ sleep(E_c')$}\;
                \textnormal{add $E_c'$ to $ Frontier$}\;
            }
        }
        \Return $Frontier$\;
    }
\end{algorithm}

\end{frame}



\begin{frame} {Scheduler Exploration Loop}

\SetKwProg{Fn}{Function}{}{}
\SetKwHangingKw{Let}{let}
\begin{algorithm}[H]
    \label{explore_loop}
    \Fn{explore\_loop($E_0$, $Budget$)}{
        $StartTime \leftarrow get\_time()$\;
        $ E \leftarrow E_0$\;
        \Repeat{$CurrentTime - StartTime > Budget \textbf{ or } size(E) \leq size(E_0)$}{
            $ E' \leftarrow explore(E)$\;
            $ E' \leftarrow plan\_more\_interleavings(E') $\;
            $ E \leftarrow get\_next\_execution\_sequence(E')$\;
            $CurrentTime \leftarrow get\_time()$\;
        }
        \textnormal{\textbf{send}  $E$ to Controller} \;
    }
\end{algorithm}

\end{frame}

\begin{frame} {Parallel source-DPOR}

\SetKwProg{Fn}{Function}{}{}
\SetKwHangingKw{Let}{let}
\begin{algorithm}[H]
    \caption{Handling Scheduler Response}
    \label{response}
    \Fn{wait\_scheduler\_response(Frontier, T)}{
        \textnormal{\textbf{receive} $E$ from a scheduler}\;
        remove $E$ from $Frontier$\;
        $E',T \leftarrow update\_execution\_tree(E, T)$\;
        \If{$E'$ has at least one backtrack entry}{
                \textnormal{add $E'$ to $Frontier$}\;
        }
        \Return $Frontier,T$;
    }
\end{algorithm}


\end{frame}


\begin{frame} {Load Balancing}

\begin{itemize}[<+->]

\item Load balancing through time-slicing.

\item Schedulers report back to Controller after their running time exceeds their budget.

\item Smaller budget leads to better load balance, but also a larger communication overhead.

\item Value of budget changes depending on the numbmer of idle schedulers.


\end{itemize}

\end{frame}

\begin{frame}  {A simple example}
\tracelong{../img/src_example/1_2.png}{Initial execution sequences.}
\end{frame}


\begin{frame}  {A simple example}
\tracelong{../img/src_example/3.png}{Scheduler 1 exploration.}
\end{frame}

\begin{frame}  {A simple example}
\tracelong{../img/src_example/5.png}{Execution Tree after Scheduler 1 reports to Controller.}
\end{frame}



\begin{frame}  {A simple example}
\tracelong{../img/src_example/4.png}{Scheduler 2 exploration.}
\end{frame}


\iffalse
\begin{frame} {Parallel optimal-DPOR - A first attempt}

While trying to parallelize optimal-DPOR following the same technique we encounter two main issues:

\begin{itemize}[<+->]
\item In the sequential optimal-DPOR calls to $Explore(E, Sleep, WuT)$ guarantee that the complete subtree rooted
at $E$ will be explored. However, for this to hold true,
all sequences in $wut(E)$ that were ordered before WuT must have been explored. This means that the concept of ownership cannot be applied to complete wakeup trees.
\item $insert_{[E]}(v,wut(E))$ may end up inserting at $wut(E)$ an execution sequence different than $v$ (but one that will lead to equivalent interleavings).
\end{itemize}

\end{frame}
\fi

\begin{frame} {Parallel optimal-DPOR - A first attempt}

Any leaf of $\langle B , \prec \rangle$ remains a leaf of $insert_{[E]}(w,\langle B , \prec \rangle)$.
\\
We use this to develop a parallel algorithm that uses:

\begin{itemize}
  \item a single planner that is responsible for race detecting interleavings sequentially.
  \item multiple schedulers that simply explore in parallel the interleavings
  that generated by the planner
  \item a Controller who is responsible for managing the queue of the planner and for assigning interleavings to schedulers for exploration
\end{itemize}

\end{frame}

\begin{frame} {Parallel optimal-DPOR - A first attempt}

This attempt fails to provide any speedup:


\smalltabular{"../tables/opttab.tex"}{Parallel optimal-DPOR performance.}

\end{frame}

\begin{frame} {Parallel optimal-DPOR - A first attempt}

Our attempt fails because:

\begin{itemize}[<+->]
\item We have parallelized the exploration phase of our algorithm, but have kept the most time consuming phase sequential.
\item We have noticed that the planner, during most of the execution of our program, does not generate enough interleavings to keep the schedulers busy.
\end{itemize}
\end{frame}

\begin{frame} {Parallel optimal-DPOR - A first attempt}

This behavior can be observed from the following graphs:

\graph{../img/bottleneck_lastzero_green.png}{Execution time for readers 10 by optimal-DPOR.}


\end{frame}


\begin{frame} {Scalable parallel optimal-DPOR}


Lets assume that we have an execution sequence $E$ and that $w$, $v$ are leaf sequences of $wut(E)$:
\begin{itemize}[<+->]
\item Assign the exploration of $E.w$ and $E.v$ to different workers-schedulers.
\item Those schedulers will explore the subtrees rooted at the assigned sequences.
\end{itemize}


\end{frame}

\begin{frame} {Changing the concept of ownership}
We need to modify the concept of ownership as follows:

\begin{itemize}[<+->]
\item A leaf sequence assigned to a scheduler is \text_bf{owned} by that scheduler. 
\item This scheduler also own every node in the subtree rooted at that leaf. If $v$ is an owned leaf sequence in $wut(E)$ a scheduler owns every execution sequence that has a prefix of $E.v$.
\item Leaf sequence assigned to different schedulers are marked as \textbf{not owned}
\item All other nodes are considered \textbf{disputed}.
\end{itemize}
\end{frame}

\begin{frame} {Resolving conflicts}

Conflicts are harder to resolve:

\begin{itemize}[<+->]
\item Conflicts occur between sequences, instead of processes.
\item $insert_{[E]}(v,wut(E))$ may end up inserting at $wut(E)$ an execution sequence different than $v$.

\end{itemize}

\end{frame}

\begin{frame} {Resolving conflicts}

To resolve them:

\begin{itemize}[<+->]
\item We modify $insert_{[E]}(v,wut(E))$ to insert sequences in the Execution Trees.
\item If a disputed sequence can be inserted into the execution tree, ownership is claimed it.
\item Otherwise, it is marked as not owned.

\end{itemize}

\end{frame}


\begin{frame} {Scalable parallel optimal-DPOR}

:

\begin{itemize}[<+->]

\end{itemize}

\end{frame}


\section{Implementation Details}


\begin{frame} {}

Here I will why erlang pids need to be the same for every process of the tested program with Concuerror

I will present how I solved it

Present disadvantages of this Distributed implementation

Should I merge this with Erlang and Concuerror brief overview in the beginning?

\end{frame}

\section{Performance Evaluation}



\begin{frame}{Benchmarks}

\begin{itemize}
\item The benchmarks were performed on a multiprocessor with 64 AMD Opteron 6276(2.3 GHz) cores, 126 GB of memory, running
Linux 4.9.0-8amd64 and running the later Erlang version (Erlang/OTP 21.1). 
\item While running our tests, we are using the
--$keep\_going$ flag to continue exploring our state space, even after an error is found. We do this so we can evaluate
how fast the complete state space gets explored, regardless of whether errors exist.
\end{itemize}

\end{frame}


\begin{frame} {Benchmarks}
Lets give a brief overview of our benchmarks:

\begin{itemize}
    \item $indexer$ $N$: This test uses a Compare and Swap (CAS) primitive instruction to check if a specific element of
    a matrix is set to 0 and if so, set it to a new value. This is implemented in Erlang by using ETS tables and specifically
    the $insert\_new/2$ function. This function returns false if the key of the inserted tuple exists (the entry is set to 0)
    or it inserts the tuple if the key is not found. $N$ refers to the number of threads that are performing this function.
    \item $readers$ $N$: This benchmark uses a writer process that writes a variable and $N$ reader processes that read that variable.
    \item $lastzero$ $N$: In this test we have $N+1$ processes that read and write on an array of $N+1$ size, which has all its 
    values initialized with zero. The first process reads the array in order to find the zero element with the highest
    index. The other $N$ processes read an array element and update the next one.
    \item $rush$ $hour$: a program that uses processes and
    ETS tables to solve the Rush Hour puzzle in parallel, using A\textasteriskcentered  search. Rush hour is a complex but self-contained (917 lines of code) program.
\end{itemize}

\end{frame}

\begin{frame}{Results for sequential algorithms}

Lets present here number of interleavings for our benchmarks, as well as their performance for sequential algorithm and the parallel algorithm with one scheduler:

\bigtabular{"../tables/synthetic_unbounded.tex"}{Sequential performance of source-DPOR and optimal-DPOR on four benchmarks.}

We can notice that the overhead for our parallel optimal-DPOR appears to be larger than the overhead of the parallel source-DPOR.
This is to be expected since updating the execution tree in the Controller should be more expensive for the optimal algorithm.


\end{frame}

\begin{frame}{Evaluation on readers 15}

\customGraph{../scripts/readers_15_10000_combo_time.png}{Performance of readers 15 with Budget of 10000.}

\end{frame}


\begin{frame}{Evaluation on readers 15}

Trying to figure out why our algorithm fails scale for readers 15:

\customGraph{../scripts/readers1510000_combined_stack.png}{Number of times schedulers stopped their execution with a Budget of 10000.}

\end{frame}


\begin{frame}{Evaluation on readers 15}

Increase budget to 30000ms:

\customGraph{../scripts/readers_15_30000_combo_time.png}{Performance of readers 15 with budget of 30000.}

\end{frame}

\begin{frame}{Evaluation on readers 15}


\customGraph{../scripts/readers1530000_combined_stack.png}{Number of times schedulers stopped their execution with a Budget of 30000.}

\end{frame}


\begin{frame}{Evaluation on readers 15}

Increasing the Budget:

\begin{itemize}
\item Reduces the performance of source-DPOR, since it causes load imbalance.
\item Increases the performance of optimal-DPOR, since finding disputed entries also leads to load balancing and therefore,
optimal-DPOR does not need as frequent load balance.
\end{itemize}

\end{frame}

\iffalse
\begin{frame}{Evaluation on rush hour}


\tracelong{../img/rushhour.png}{Input of rush hour}


\end{frame}
\fi

\begin{frame}{Evaluation on rush hour}

\customGraph{../scripts/rush_hour_10000_combo_time.png}{Performance of rush hour with Budget of 10000 for source and 30000 for optimal.}


\end{frame}


\begin{frame}{Evaluation on rush hour}

Both of our algorithms provide high speed and decent scalability on this test case.
However, after 24 schedulers we notice that the scalability of optimal-DPOR starts to break. This is because:

\begin{itemize}
\item the communication between the Controller and the schedulers in the case of optimal-DPOR is substantially more frequent.
\item the $update\_execution\_tree$ function in optimal-DPOR is more ``expensive". 
\item each execution sequence send between the schedulers and the Controller of the optimal-DPOR is larger, since it also contains wakeup trees from other fragments
\end{itemize}

\end{frame}

\begin{frame}{Evaluation on indexer}

TODO add evaluation of indexer and lastzero

\end{frame}

\begin{frame}{Conclusion}

\begin{itemize}
\item We managed to develop parallel versions for both source-DPOR and optimal-DPOR algorithms.
\item We showed that developing a parallel version that is based on sequentially race detecting interleavings and exploring them in parallel will fail to provide any substantial speedup.
\item We implemented our algorithms on Concuerror, while encountering and solving complex implementation issues.
\item We showed that our algorithms achieve good speedups and even continue to scale up to 32 schedulers (24 for optimal-DPOR) on specific benchmarks.
\end{itemize}

\end{frame}


\begin{frame}{Bibliography}

Add Bibliography??

\end{frame}


\begin{frame}{}



\end{frame}

\end{document} 
